# Dynamic Workforce Shift & Exception Analytics â€” Demo Output

## What this demo contains

- Sample raw attendance CSV: `sample_data/attendance_sample.csv`

- Processed work sessions: generated by ETL.

- Quickstart steps to run locally.

- One-page summary screenshot: `demo_summary.png`



## Quick highlights

- Demonstrates handling of mid-shift registration, night shifts crossing midnight, shift swaps, missed punches, double-badge detection, cross-facility movements.

- Provides API endpoints and a Streamlit dashboard to explore sessions and exceptions.



## Quickstart (short)

1. Install dependencies: `pip install -r requirements.txt`

2. Generate data: `python src/data/synthetic_generator.py --out output/sample_data/attendance_sample.csv --rows 5000`

3. Run ETL: `python src/etl/etl_spark.py --input output/sample_data/attendance_sample.csv --output output/processed`

4. Start API: `uvicorn src.api.app:app --reload --port 8000`

5. Start dashboard: `streamlit run src/dashboard/app.py --server.port 8501`

6. Open `http://localhost:8501` to view dashboard.



## What to inspect

- `work_sessions.csv`: computed worked hours and exception codes

- `/api/employee/{id}/work_sessions`: inspect individual history

- Streamlit dashboard: heatmap, exception timeline, and session explanations



## Notes & next steps

- This is a demo implementation. For production: secure APIs, persistence with Postgres or data lake, deploy Spark on cluster, integrate with Kafka for streaming.

